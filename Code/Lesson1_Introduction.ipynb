{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_january = pd.read_parquet (r'D:\\Python\\Projects\\NL_Automated_Reports\\Testing\\Data\\fhv_tripdata_2021-01.parquet')\n",
    "df_february = pd.read_parquet (r'D:\\Python\\Projects\\NL_Automated_Reports\\Testing\\Data\\fhv_tripdata_2021-02.parquet')\n",
    "df = pd.concat([df_january, df_february])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration']= ((df.dropOff_datetime - df.pickup_datetime ).dt.total_seconds())/60\n",
    "df.PUlocationID = df.PUlocationID.astype(str)\n",
    "df.DOlocationID = df.DOlocationID.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154112, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df.pickup_datetime.dt.month==1]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1154112 entries, 0 to 1154111\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1154112 non-null  object        \n",
      " 1   pickup_datetime         1154112 non-null  datetime64[ns]\n",
      " 2   dropOff_datetime        1154112 non-null  datetime64[ns]\n",
      " 3   PUlocationID            195845 non-null   float64       \n",
      " 4   DOlocationID            991892 non-null   float64       \n",
      " 5   SR_Flag                 0 non-null        object        \n",
      " 6   Affiliated_base_number  1153227 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(3)\n",
      "memory usage: 61.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>nan</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>8.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>nan</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>15.216667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00          nan   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00          nan   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00          nan   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26          nan   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44          nan   \n",
       "\n",
       "  DOlocationID SR_Flag Affiliated_base_number    duration  \n",
       "0          nan    None                 B00009   17.000000  \n",
       "1          nan    None                 B00009   17.000000  \n",
       "2          nan    None                 B00013  110.000000  \n",
       "3         72.0    None                 B00037    8.283333  \n",
       "4         61.0    None                 B00037   15.216667  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration']= ((df.dropOff_datetime - df.pickup_datetime ).dt.total_seconds())/60\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195845.000000</td>\n",
       "      <td>991892.000000</td>\n",
       "      <td>1.154112e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139.859690</td>\n",
       "      <td>135.898030</td>\n",
       "      <td>1.916722e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>74.991382</td>\n",
       "      <td>80.474902</td>\n",
       "      <td>3.986922e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>7.766667e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1.340000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>206.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>2.228333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>4.233710e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PUlocationID   DOlocationID      duration\n",
       "count  195845.000000  991892.000000  1.154112e+06\n",
       "mean      139.859690     135.898030  1.916722e+01\n",
       "std        74.991382      80.474902  3.986922e+02\n",
       "min         1.000000       1.000000  1.666667e-02\n",
       "25%        75.000000      67.000000  7.766667e+00\n",
       "50%       143.000000     132.000000  1.340000e+01\n",
       "75%       206.000000     213.000000  2.228333e+01\n",
       "max       265.000000     265.000000  4.233710e+05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <td>dispatching_base_num</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_datetime</th>\n",
       "      <td>pickup_datetime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <td>dropOff_datetime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <td>Affiliated_base_number</td>\n",
       "      <td>0.076682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOlocationID</th>\n",
       "      <td>DOlocationID</td>\n",
       "      <td>14.055828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUlocationID</th>\n",
       "      <td>PUlocationID</td>\n",
       "      <td>83.030676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR_Flag</th>\n",
       "      <td>SR_Flag</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   column_name  percent_missing\n",
       "dispatching_base_num      dispatching_base_num         0.000000\n",
       "pickup_datetime                pickup_datetime         0.000000\n",
       "dropOff_datetime              dropOff_datetime         0.000000\n",
       "duration                              duration         0.000000\n",
       "Affiliated_base_number  Affiliated_base_number         0.076682\n",
       "DOlocationID                      DOlocationID        14.055828\n",
       "PUlocationID                      PUlocationID        83.030676\n",
       "SR_Flag                                SR_Flag       100.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df_train.isnull().sum() * 100 / len(df_train)\n",
    "missing_value_df = pd.DataFrame({'column_name': df_train.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1154112 entries, 0 to 1154111\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1154112 non-null  object        \n",
      " 1   pickup_datetime         1154112 non-null  datetime64[ns]\n",
      " 2   dropOff_datetime        1154112 non-null  datetime64[ns]\n",
      " 3   PUlocationID            1154112 non-null  object        \n",
      " 4   DOlocationID            1154112 non-null  object        \n",
      " 5   SR_Flag                 0 non-null        object        \n",
      " 6   Affiliated_base_number  1153227 non-null  object        \n",
      " 7   duration                1154112 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(1), object(5)\n",
      "memory usage: 70.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1154112 entries, 0 to 1154111\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1154112 non-null  object        \n",
      " 1   pickup_datetime         1154112 non-null  datetime64[ns]\n",
      " 2   dropOff_datetime        1154112 non-null  datetime64[ns]\n",
      " 3   PUlocationID            1154112 non-null  object        \n",
      " 4   DOlocationID            1154112 non-null  object        \n",
      " 5   SR_Flag                 0 non-null        object        \n",
      " 6   Affiliated_base_number  1153227 non-null  object        \n",
      " 7   duration                1154112 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(1), object(5)\n",
      "memory usage: 70.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.PUlocationID = df.PUlocationID.astype(str)\n",
    "df. DOlocationID = df.DOlocationID.astype(str)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>nan</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>8.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>nan</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "      <td>15.216667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00          nan   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00          nan   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00          nan   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26          nan   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44          nan   \n",
       "\n",
       "  DOlocationID SR_Flag Affiliated_base_number    duration  \n",
       "0          nan    None                 B00009   17.000000  \n",
       "1          nan    None                 B00009   17.000000  \n",
       "2          nan    None                 B00013  110.000000  \n",
       "3         72.0    None                 B00037    8.283333  \n",
       "4         61.0    None                 B00037   15.216667  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:395: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_array(X, dtype=np.int)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_int = np.zeros((n_samples, n_features), dtype=np.int)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:111: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1154112x525 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2308224 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "X = df[['PUlocationID', 'DOlocationID', 'duration']]\n",
    "X_train,y_train = X.drop('duration', axis=1), X.duration\n",
    "cat_features = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "def feature_transformation(X,cat_features):\n",
    "    # Define Transformers                                                                       \n",
    "    #categorical_transformer = OrdinalEncoder()\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    t = [(('cat', categorical_transformer, cat_features))]\n",
    "    preprocesor = ColumnTransformer(transformers = t,remainder='passthrough' )\n",
    "\n",
    "    steps = [('preprocesor',preprocesor),\n",
    "         \n",
    "        ]\n",
    "# define the pipeline\n",
    "    pipeline = Pipeline(steps=steps) \n",
    "    X_scaled = pipeline.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "X_train_scaled =  feature_transformation(X_train,cat_features)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* DummyRegressor_mean\n",
      "* LinearRegression\n",
      "* Lasso\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>mean_squared_error_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.822083</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyRegressor_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.979194</td>\n",
       "      <td>0.063666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.979194</td>\n",
       "      <td>0.063666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model run_time  root_mean_squared_error  \\\n",
       "1     LinearRegression     0.46                 2.822083   \n",
       "0  DummyRegressor_mean      0.0                 2.979194   \n",
       "2                Lasso     0.05                 2.979194   \n",
       "\n",
       "   mean_squared_error_std  \n",
       "1                0.044539  \n",
       "0                0.063666  \n",
       "2                0.063666  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "#from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from math import sqrt\n",
    "import warnings\n",
    "\n",
    "\n",
    "def getting_data():\n",
    "    df  = pd.read_parquet (r'D:\\Python\\Projects\\NL_Automated_Reports\\CRM\\Predictive_Models\\Applications_v1\\Data\\train_data.parquet')\n",
    "    X, y = df.drop(['App'], axis=1).dropna(), df.dropna()['App']\n",
    "    return X,y\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def feature_transformation(X):\n",
    "   # Define Transformers                                                                       \n",
    "    #categorical_transformer = OrdinalEncoder()\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    t = [(('cat', categorical_transformer, cat_features))]\n",
    "    preprocesor = ColumnTransformer(transformers = t,remainder='passthrough' )\n",
    "\n",
    "    steps = [('preprocesor',preprocesor),\n",
    "         \n",
    "        ]\n",
    "# define the pipeline\n",
    "    pipeline = Pipeline(steps=steps) \n",
    "    X_scaled = pipeline.fit_transform(X)\n",
    "    return X_scaled\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "\n",
    "def fit_model(y, X_scaled):\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        regressors = {\n",
    "        \"DummyRegressor_mean\": DummyRegressor(strategy='mean'),    \n",
    "        #\"LGBMClassifier\": LGBMClassifier(),\n",
    "       # \"XGBRegressor\": XGBRegressor(),\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        #\"KNeighborsRegressor\": KNeighborsRegressor(3),    \n",
    "        #\"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "        #\"RandomForestRegressor\": RandomForestRegressor(),\n",
    "        #\"AdaBoostRegressor\": AdaBoostRegressor(),\n",
    "        #\"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "        \"Lasso\":Lasso(),\n",
    "        #\"BaggingRegressor\":BaggingRegressor(),\n",
    "        #\"ExtraTreesRegressor\":ExtraTreesRegressor(),\n",
    "        #\"SVR\":SVR(),\n",
    "        #\"NN\":MLPRegressor(),\n",
    "        }\n",
    "\n",
    "\n",
    "        df_models = pd.DataFrame(columns=['model', 'run_time', 'root_mean_squared_error', 'mean_squared_error_std'])\n",
    "        \n",
    "        for key in regressors:\n",
    "            print('*',key)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            regressor = regressors[key]\n",
    "    \n",
    "            model = regressor.fit(X_scaled, y)\n",
    "\n",
    "            cv = cross_val_score(model, X_scaled, y, cv=2, scoring='neg_mean_absolute_error')\n",
    "\n",
    "            row = {'model': key,\n",
    "            'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "            'root_mean_squared_error': sqrt(cv.mean()*(-1)),\n",
    "            'mean_squared_error_std': cv.std(),\n",
    "        }\n",
    "\n",
    "            df_models = df_models.append(row, ignore_index=True)\n",
    "        return df_models\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "X_scaled = feature_transformation(X_train)\n",
    "df_models = fit_model(y_train, X_scaled)\n",
    "df_models.sort_values(by='root_mean_squared_error', ascending=True,inplace=True)\n",
    "df_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transformation(X,cat_features):\n",
    "    # Define Transformers                                                                       \n",
    "    #categorical_transformer = OrdinalEncoder()\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "    t = [(('cat', categorical_transformer, cat_features))]\n",
    "    preprocesor = ColumnTransformer(transformers = t,remainder='passthrough' )\n",
    "\n",
    "    steps = [('preprocesor',preprocesor),     \n",
    "        ]\n",
    "# define the pipeline\n",
    "    pipeline = Pipeline(steps=steps) \n",
    "    X_scaled = pipeline.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "df_train_copy= df_train[(df_train.duration>=1) & (df_train.duration<=60)].copy(deep=True)\n",
    "X = df_train_copy[['PUlocationID', 'DOlocationID', 'duration']]\n",
    "\n",
    "X_train,y_train = X.drop('duration', axis=1), X['duration'].values\n",
    "cat_features = ['PUlocationID', 'DOlocationID']\n",
    "X_scaled = feature_transformation(X_train,cat_features)\n",
    "regressor = LinearRegression()\n",
    "model = regressor.fit(X_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519107204994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = model.predict(X_scaled)\n",
    "rmse = sqrt(mean_squared_error(y_train, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_scaled)\n",
    "rmse = sqrt(mean_squared_error(y_train, predictions))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_january['duration']= ((df_january.dropOff_datetime - df_january.pickup_datetime ).dt.total_seconds())/60\n",
    "df_january = df_january[(df_january.duration >= 1) & (df_january.duration <= 60)]\n",
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "numerical = ['duration']\n",
    "df_january[categorical] = df_january[categorical].astype(str)\n",
    "train_dicts = df_january[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1109826x526 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3329478 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_february['duration']= ((df_february.dropOff_datetime - df_february.pickup_datetime ).dt.total_seconds())/60\n",
    "df_february = df_february[(df_february.duration >= 1) & (df_february.duration <= 60)]\n",
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "numerical = ['duration']\n",
    "df_february[categorical] = df_february[categorical].astype(str)\n",
    "train_dicts = df_february[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_test = dv.fit_transform(train_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<990113x527 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2970339 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c3d2a7ebe72664db43713df5f1022afde1f70ae801b238f747d404c3b87518b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
